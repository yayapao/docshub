---
id: kafka
title: ''
sidebar_label: kafka
---

import { DocsHeader } from '/src/components/Layout/DocsHeader'

<DocsHeader
  title="Apache Kafka"
  description="An open-source distributed event streaming platform."
  github="https://github.com/apache/kafka"
  tags={['distributed', 'streaming']}
  links={[
    {
      label: 'Nestjs kafka',
      link: 'https://docs.nestjs.com/microservices/kafka',
    },
    {
      label: 'Kafka分区与消费者的关系kafka分区和消费者线程的关系',
      link: 'https://cloud.tencent.com/developer/article/1953243',
    },
  ]}
/>{' '}

## Kafka Commands

通过 Docker 进入控制台后，查看 Topic 相关信息

```bash
cd usr/bin

# 查看 topics
kafka-topics --zookeeper sentry_zookeeper:2181 --list

# 查看 topic 详细信息
kafka-topics --zookeeper sentry_zookeeper:2181 --describe --topic ingest-events

# 查看 topic 内容
kafka-console-consumer --bootstrap-server sentry_kafka:9092 --topic ingest-events --from-beginning

# 创建一个 partition 为 1 且名为 mytopic 的 topic
kafka-topics --zookeeper sentry_zookeeper:2181 --create --replication-factor 1 --partitions 1 --topic mytopic
```

查看 consumer-groups 相关信息

```bash
# 查看 groups
kafka-consumer-groups --bootstrap-server sentry_kafka:9092 --list

# 查看 group 详情
kafka-consumer-groups --bootstrap-server sentry_kafka:9092 --describe --group ingest-consumer
```

## Consumer

### 手动提交 offsets vs 自动提交 offsets

以下选自 sentry 关于 kafka consumer 的实现 `class BatchingKafkaConsumer`，它是手动提交 offset。

- Messages are processed locally (e.g. not written to an external datastore!) as they are read from Kafka, then added to an in-memory batch
- Batches are flushed based on the batch size or time sent since the first message in the batch was received (e.g. "500 items or 1000ms")
- Kafka offsets are not automatically committed! If they were, offsets might be committed for messages that are still sitting in an in-memory batch, or they might _not_ be committed when messages are sent to an external datastore right before the consumer process dies
- Instead, when a batch of items is flushed they are written to the external datastore and then Kafka offsets are immediately committed (in the same thread/loop)
- Users need only provide an implementation of what it means to process a raw message and flush a batch of events
- Supports an optional "dead letter topic" where messages that raise an exception during `process_message` are sent so as not to block the pipeline.

### Consumer Group

消费组(Consumer Group)是消费者的集合，它的出现可以解决：

- 分担消费节点的压力，可以在 group 扩容机器
- 同一份 topic 可以被不同 consumer group 分别消费，维持独自的 offset

![consumer-group](/img/database/consumer-group.png)

:::caution

- 一条消息只能被消费组内一个消费者实例消费
- 一个 partition 只能被组内一个消费者实例负责(一对一)
- 一个消费者实例能够负责多个 partition(一对多)

:::

消费者组是一种**广播模式**。一个消费者组内对 topic 的消费不会影响其他消费者组。

### 分配策略

**为什么一个 partition 只能被一个消费者实例消费？**

因为必须保证 partition 下消息消费的顺序。如果多个消费者读取同一个 partition 消息，那么肯定会存在不同的 offset，这样会造成消息被重复处理，与主动推送无异了。

因此，当出现消息积压时，当扩容超过 partition 个数时，多余的机器在空跑，并不会被分配到 partition。

**Kafka 如何保证 topic 内的一条消息仅被一个消费者实例消费？**

得益于 kafka 的 **partition 分配策略** 和 **offset 管理**

**kafka 如何维护不同 group 提交的 offset？**

如果一个 topic 被多个 consumer group 同时消费，直接将各个分组的 offset commit 到 Broker 服务器会产生很大的负载。因此 kafka 将 \_consumer_offsets 设定拥有 50 个分区，从而将其均匀分布到不同机器上，通过负载均衡来将不同的 commit offsets 请求交给不同的机器处理。

**partition reblancing 的场景**

- 有消费者退出/加入
- 订阅 topic 的 partition 发生变化

Rebalance 给消费者群组带来了高可用性与伸缩性，但是在 Rebalance 期间，消费者无法读取消息，整个群组一小段时间不可用，而且当分区被重新分配给另一个消费者时，消费者当前的读取状态会丢失

分配策略：

- range 默认策略，基于 topic。将 partition 排序后，依次指定。
- roundrobin 策略，会将消费组内所有消费者以及消费者所订阅的所有 topic 的 partition 按照字典序排序，然后通过轮询算法逐个将分区以此分配给每个消费者。
