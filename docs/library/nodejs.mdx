---
id: nodejs
title: Node.js Packages
sidebar_label: Node.js
slug: nodejs
---

import {
  HighlightWithCode,
} from '@site/src/components/Highlights'

[cross-env](https://github.com/kentcdodds/cross-env) - 解决了 node 的环境变量在不同平台的 (eg: `NODE_ENV=production`) 的设置兼容性问题

## zx

:::note zx
[zx](https://github.com/google/zx) 是一个 Google 的 util 脚本工具，基于 Node.js 的 child_process 对 shell 进行封装，能以接近 ES6 的语法来编写 bash 脚本
:::

我们通常在 `.mjs` 文件对编写 zx 脚本，它具备如下特性：

- 支持大部分的 node.js 特性和语法
- 能够转换 [bash 命令](https://github.com/google/zx#functions)
- 内置编写脚本的[常用依赖](https://github.com/google/zx#packages)

这里我们直接以一个例子开始：

```js
#!/usr/bin/env zx

import dayjs from 'dayjs'

const log = console.log
const ALERT_MESSAGE = '\nPlease confirm your input!\n'
const cmds = ['tag']

/**
 * 判断是否传递命令行参数
 * 如果传递，则直接获取参数，并将其丢入 switch 内进行判断
 * 如果没传递，则通过 question(readline) 来引导用户传入
 * 注意：两种方式获取的参数类型不一样，前者为数据，后者为空格拼接的字符串
 */
const [nodePath, zxPath, scriptName, ...restData] = process.argv
let choose
if (!restData || restData.length === 0) {
  const crt = await question('Choose command: ', {
    choices: cmds,
  })
  // 处理字符串
  choose = crt.split(' ')
} else {
  choose = restData
}

// 根据参数进行路由判断
const [target, ...rest] = choose
switch (target) {
  case 'tag':
    tag(...rest)
    break
  default:
    log(chalk.red(ALERT_MESSAGE))
    log(`Support command ===> ${cmds.join(' ')}`)
}

// 生成 tag，并推送到 git
async function tag(name) {
  let tagName = name

  if (!name) {
    const COMMIT_ID = await $`git rev-parse --short HEAD`
    const COMMIT_NAME = String(COMMIT_ID).trim()
    tagName = COMMIT_NAME
  }

  log(chalk.blue(`Tag name is ${tagName}`))
  const dt = dayjs().format('YYYY-MM-DD HH:mm:ss')
  await $`git tag -a ${tagName} -m "Created at ${dt}"`
  await $`git push --tag`
  log(chalk.black.bgGreen.bold(`Successfully tag at ${Date.now()}`))
}
```

如上脚本所示，我们在一行申明 <HighlightWithCode>#!/usr/bin/env zx</HighlightWithCode> 之后，就可以编写相关的执行脚本，通过 <HighlightWithCode>const res = await $`bash command`</HighlightWithCode>的形式来执行原生 bash 命令，同时我们会根据用户输入的命令行参数来执行不同的动作。

### 如何获取命令行内参数？

在执行类似 `zx control.mjs build params1 params2` 命令时，我们可以通过 [node.js-process.argv](http://nodejs.cn/api/process/process_argv.html) 来获取执行参数

相较于 `node control.js` 直接执行指定脚本的形式，通过 zx 执行会存在一点区别：通常来说，`process.argv` 返回一个指定顺序的数组：

1. 第一个元素是 `process.execPath`, 通常是 node 的执行文件路径；
2. 第二个元素是正在执行的 javascript 文件，由于 zx 作为中间层，因此在执行 zx 脚本时，指向的是 zx 的执行文件路径，**区别就在于此**；
3. 剩下的会按照顺序依次填入数组；





## NEL

> [NEL](https://w3c.github.io/network-error-logging/) defines a mechanism that enables developers to declare a network error reporting policy for a web application

页面错误最严重的一种情况就是完全获取不到特定的资源，这可能是网络错误、加载资源发生错误，DNS 解析错误等原因造成的，并且这种错误难以复现，因此我们需要一个机制来处理此类情况，即当一个网络错误发生时，客户端能够上报 <b>在何时何处发生了什么事件，以及该类事件为何发生</b>

服务端无法完全处理此类错误，因为客户端可能还未与服务端建立连接就已经发生错误了，此时服务端根本无法察觉到

NEL(network-error-logging) 就是用来处理这类问题的一个机制，当客户端请求错误发生时，客户端 agent 会将该错误的类型、时间戳等信息进行解析并放入队列，然后通过读取队列将错误日志上报到指定位置。同时，它也支持上报正常的请求，用来统计不同客户群体内的错误率

## PM2

> Advanced, production process manager for Node.js. It can keep your application online 24/7

github: [pm2](https://github.com/Unitech/pm2)

Install -> `npm i -g pm2@latest` or `npm i -D pm2@latest`

Update pm2 version -> `pm2 update`

[CLI completion](https://pm2.keymetrics.io/docs/usage/auto-completion/) -> `pm2 completion install` and `source ~/.zsh`

Start with PM2 apis -> see `pm2.js` and `package.json` for details

### Cluster mode

> 用来最大化使用 CPU 资源

Node.js 本身异步 IO 是基于线程池（thread pool）实现的，因此 Node.js 运行时内会看到多个 thread，但是实际执行 javascript 的部分是单线程，所以只能利用到单核 CPU 的资源，无法有效利用多核 CPU，容易造成一个 CPU 很忙，但是其他 CPU 很闲的情况！

PM2 的集群模式（cluster mode）利用 Node.js 提供的 cluster 来用来解决多核 CPU 的利用率问题。Node.js 提供的集群模式能够让应用的子进程共享服务端口。但是在实际使用过程中，我们碰到了一些问题：

Q1: 在集群模式下，设置 `instance` 数量如果超过机器本身 CPU 核数，在重启服务时会产生**只有部分实例被重启的问题**<

我们在一个 _2.3 GHz 四核 Intel Core i5_ 的机器下，设置 start 参数为 `{ exec_mode: 'cluster', instances: '16' }`，之后执行 start 命令:

![pm2_start](/img/package/nodejs/pm2_start.png)

此时，各个服务正常，之后我们执行 `pm2 restart upserver_lifer` 看看会发生什么

![restart](/img/package/nodejs/pm2_start_1.png)

发现 id 为 19 和 23 的服务被重启了两次，在实际访问过程中的具体表现就是会有 1/8 的概率（假设各个服务访问概率相等）访问到这两个服务，接着我们执行 `pm2 reload upserver_lifer`

![reload](/img/package/nodejs/pm2_start_2.png)

分歧更加扩大，更致命的是 id 为 18 的子进程没有重启，这意味着 1/16 的概率我们会访问到旧的服务，不管怎样，各个进程间的不一致会造成程序的错误执行和返回，在生产上是不被允许的

解决方案：将参数设置为 `{instance: 'max'}` 或者小于主机的 CPU 核数

### pm2-logrotate

[pm2-logrotate](https://github.com/keymetrics/pm2-logrotate) 用来扩展 pm2 的日志管理功能

原生日志功能的设计缺陷：

- 没有日志分割功能，一个应用会产生两个日志文件，
- 无法自动清理，日积月累后日志文件会增大，增加排查难度，一些“陈年日志”，已经失去价值，但是仍然占据磁盘空间

为此，pm2-logrotate 用来进行日志管理，根据配置规则对日志进行合理切割

```bash
# install
$ pm2 install pm2-logrotate

# 设置一个文件最磁盘
$ pm2 set pm2-logrotate:max_size 50M
# 设置切割规则
$ pm2-logrotate:rotateInterval '0 0 0 * * ? '
# 设置日志保存时间
pm2 set pm2-logrotate:retain 300
```

## Typeorm

具体使用方法参考：

- [Typeorm 中文文档](https://typeorm.bootcss.com/)
- [nestjs Database](https://docs.nestjs.com/techniques/database)

这里我们主要记录在使用过程中碰到的问题：

### Q&A

[Cannot use import statement outside a module](https://stackoverflow.com/questions/59435293/typeorm-entity-in-nestjs-cannot-use-import-statement-outside-a-module)

- 场景：当使用 `typeorm.conf.ts` 的方式来引入配置时，想使用 `/**/*.entity.{ts,js}` 的方式来通配所有实体

- 原因：当使用 nestjs 的 monorepo 模式时，实际执行内容是 webpack 编译后的内容，在 .js 文件内引入 .ts 类型文件会报错

- 解决：
  1. 依次引入各个 entity 类后进行配置
  2. 参考 https://docs.nestjs.com/techniques/database#auto-load-entities 配置 `autoLoadEntities: true`

innerJoinAndSelect 使用问题

- `getMany()` 的返回值是 typeorm 对原生返回值处理后的结果，可能会过滤掉实力内不存在的值，并且对值的类型做转换，因此复杂的查询建议用 `getRawMany()`
- 在下面这种情况下，`getRawMany()` 返回的值也不一致，在数据库内是 `2021-09-04` ，但是查询出来是 `"2021-09-04T16:00:00.013Z"` ，是一个 ISOString 类型，解决方案是在 select 时通过 `'DATE_FORMAT(w.dt, "%Y-%m-%d") as dt'` 对其进行格式化操作

```typescript
crt = this.weightRegistry
  .createQueryBuilder('w')
  .innerJoinAndSelect('user', 'u', 'u.id = w.userId')
  // Date 类型使用 getRawMany 查询出来会是 ISOString，因此这里做一层转换，与横坐标对应
  .select([
    'w.value as value',
    'DATE_FORMAT(w.dt, "%Y-%m-%d") as dt',
    'u.name as name',
  ])
  .where('w.dt BETWEEN :st AND :et', { st, et })
  .andWhere('w.userId = :userId', { userId: +userId })
  .orderBy('w.dt', 'ASC')

// getMany() 只返回当前实体的转换后的结果
const data = await crt.getRawMany()
```

## Puppeteer

> Puppeteer is a Node library which provides a high-level API to control Chrome or Chromium over the DevTools Protocol.

简单来说，puppeteer 就是一个在 Node.js runtime 内的浏览器组件库，提供浏览器内核和系统的底层支持

### Ubuntu 依赖及字体安装

参考 [https://developers.google.com/web/tools/puppeteer/troubleshooting#chrome_headless_doesnt_launch_on_unix](https://developers.google.com/web/tools/puppeteer/troubleshooting) 了解在 docker 或者真实 Lunix 环境下，我们需要安装的依赖

但是在利用 puppeteer 进行截图服务时，发现截图字体是楷体，字体本身和标点符号效果不好

![pp-before](/img/package/nodejs/pp-snapshot-1.png)

因此我们希望能够采用字体 [Material 推荐的 Roboto](https://material-ui.com/zh/components/typography/#general) 和微软雅黑来对页面进行样式上的调整，最终呈现效果如下图：

![pp-after](/img/package/nodejs/pp-snapshot-2.png)

相关配置参考：

- `fc-list` 查看以安装的字体
- `fc-list :lang=zh` 查看中文字体依赖
- `fc-cache -f -v` 刷新字体缓存

```shell
# 下载相关依赖和字体依赖
RUN apt-get update && \
    apt-get install -yq --no-install-recommends ca-certificates fonts-liberation libappindicator3-1 libasound2 libatk-bridge2.0-0 libatk1.0-0 libc6 libcairo2 \
    libcups2 libdbus-1-3 libexpat1 libfontconfig1 libgbm1 libgcc1 libglib2.0-0 libgtk-3-0 libnspr4 libnss3 libpango-1.0-0 libpangocairo-1.0-0 libstdc++6 libx11-6 \
    libx11-xcb1 libxcb1 libxcomposite1 libxcursor1 libxdamage1 libxext6 libxfixes3 libxi6 libxrandr2 libxrender1 libxss1 libxtst6 lsb-release \
    xdg-utils xfonts-utils fonts-roboto;

# 下载对应字体
# mkfontscale 控制字体旋转缩放
# mkfontdir 创建雅黑字体的fonts.dir文件，它用来控制字体粗斜体产生
# fc-cache 建立字体缓存信息，也就是让系统认识雅黑
RUN wget -P /tmp/ https://iyoyo.oss-cn-hangzhou.aliyuncs.com/mirror/fonts/msyh.ttf  && \
    wget -P /tmp/ https://iyoyo.oss-cn-hangzhou.aliyuncs.com/mirror/fonts/msyhbd.ttf && \
    wget -P /tmp/ https://iyoyo.oss-cn-hangzhou.aliyuncs.com/mirror/fonts/msyhl.ttf &&\
    mkdir /usr/share/fonts/winFont && \
    cp /tmp/*.ttf /usr/share/fonts/winFont/ && \
    chmod 755 -R /usr/share/fonts/winFont/*.ttf && \
    cd /usr/share/fonts/winFont/ && \
    mkfontscale && mkfontdir && fc-cache -f -v;

# 关键一步：删除系统默认字体，中文字体会按照 fontconfig 的顺序进行加载
RUN apt-get purge -y fonts-arphic-ukai fonts-arphic-uming && fc-cache -f -v;
```

### 性能优化

关于内存共享，Chrome 默认使用 /dev/shm 共享内存，但是 docker 默认 /dev/shm 只有 64MB（通过会在容器内发布应用），在不够用的情况下，解决方案：

- 启用 docker 时添加启动参数 `--shm-size=1gb` 来增大 /dev/shm 的共享内存
- 启动 Chrome 时添加参数 `-disable-dev-shm-usage` 来禁止使用共享内存

一些性能优化思路：

- 尽量使用同一个浏览器实例，实现缓存公用
- 拦截不必要的资源
- 有效控制同时打开 tab 的数量
- 一个 Chrome 实例打开久了难免会产生内存泄漏，可以通过定时器任务来定时重启 Chrome 实例
- 关闭没必要的配置：`-no-sandbox,--disable-extensions`

## multer

> Multer 是一个 node.js 中间件，用于处理 multipart/form-data 类型的表单数据，它主要用于上传文件

通过 `npm install --save @koa/multer multer` 来安装 [multer](https://github.com/koajs/multer)

[原文档，用来参考配置](https://github.com/expressjs/multer/blob/master/doc/README-zh-cn.md)

```js
import Router from 'koa-router'
import Compose from 'koa-compose'
import multer from '@koa/multer'
import utils from 'utility'

const uploadRouter = new Router()
// 创建文件存储规则
const storage = multer.diskStorage({
  // 文件存放路径，从文件根目录开始寻找
  destination: (req, file, cb) => {
    cb(null, 'upload')
  },
  // 重命名文件
  filename: (req, file, cb) => {
    // 格式化文件后缀
    const fileArray = file.originalname.split('.')
    const prefix = fileArray[0]
    const suffix = fileArray[1]
    // 添加时间戳，避免文件名重复
    cb(null, `${Date.now()}-${utils.md5(prefix)}.${suffix}`)
  },
})
// 创建文件上传限制
const limits = {
  //非文件字段的数量
  fields: 10,
  //文件大小 单位 b，3M
  fileSize: 10 * 1024 * 1024,
  //文件数量
  files: 1,
}

let upload = multer({ storage: storage, limits: limits })

// upload.single('file') 表示接受一个以 ‘file’ 命名的文件，且这个文件的信息保存在 ctx.request.file 字段内
// 文件上传错误，可以直接通过 try catch 进行捕获
uploadRouter.post('/upload', upload.single('file'), async (ctx) => {
  try {
    // 获取上传文件
    const file = ctx.request.file
    const results = {
      success: true,
      name: file.originalname,
      status: 'done',
      url: `http://192.168.1.103:7777/pics/${file.filename}`,
    }
    ctx.body = results
  } catch (e) {
    ctx.app.emit('error', e, ctx)
  }
})

const router = new Router()
router.use('/service', uploadRouter.routes(), uploadRouter.allowedMethods())

const router_routes = router.routes()
const router_allow_methods = router.allowedMethods()
const uploadCompose = Compose([router_routes, router_allow_methods])

export default uploadCompose
```

## Axios

> [axios](https://github.com/axios/axios) 现在是一种常见的客户端数据请求库，它基于 XMLHttpRequest 和 Promise

### 取消重复请求

核心思想利用`set`数据结构，维护一个 pending set，里面存放 key(通过 url.config 拼接)和 value(取消改请求的 cacel 方法)

```js
import axios from 'axios'
import { message } from 'ant-design-vue'

// 声明一个 Map 用于存储每个请求的标识 和 取消函数
const pending = new Map()

// 通过工厂方法创建 canceltoken，用于取消用户请求
let CancelToken = axios.CancelToken
let source = CancelToken.source()

// axios 实例
let service = axios.create({
  //   baseURL: "/service/",
  timeout: 60000,
  headers: {},
  withCredentials: true,
})

const addPending = (config) => {
  const url = [
    config.method,
    config.url,
    JSON.stringify(config.params),
    JSON.stringify(config.data),
  ].join('&')
  config.cancelToken =
    config.cancelToken ||
    new axios.CancelToken((cancel) => {
      if (!pending.has(url)) {
        // 如果 pending 中不存在当前请求，则添加进去
        pending.set(url, cancel)
      }
    })
}

const removePending = (config) => {
  const url = [
    config.method,
    config.url,
    JSON.stringify(config.params),
    JSON.stringify(config.data),
  ].join('&')
  if (pending.has(url)) {
    // 如果在 pending 中存在当前请求标识，需要取消当前请求，并且移除
    const cancel = pending.get(url)
    cancel(url)
    pending.delete(url)
  }
}

export const clearPending = () => {
  for (const [url, cancel] of pending) {
    cancel(url)
  }
  pending.clear()
}

// 设置请求拦截器
service.interceptors.request.use(
  (config) => {
    removePending(config) // 在请求开始前，对之前的请求做检查取消操作
    addPending(config) // 将当前请求添加到 pending 中
    return config
  },
  (error) => {
    return Promise.reject(error)
  }
)

// 设置响应拦截器
service.interceptors.response.use(
  (response) => {
    removePending(response.config) // 在请求结束后，移除本次请求
    return response
  },
  (error) => {
    if (axios.isCancel(error)) {
      // 再次尝试 cancel
      console.error(error.message)
    }
    return Promise.reject(error)
  }
)

/**
 * config.params 用来接受查询参数
 */
async function get(url, config = {}) {
  try {
    const response = await service.get(url, config)
    // 返回服务器传值
    return response.data
  } catch (e) {
    throw e
  }
}

/**
 * params 用来接收查询参数
 */
async function post(url, params, config = {}) {
  try {
    const response = await service.post(url, params, config)
    // 返回服务器传值
    return response.data
  } catch (e) {
    throw e
  }
}

export { get, post }
```

## Highcharts

### 两个散点图的 tooltips 联动

思路就是将两个散点图数据的共有属性之一传入 ID，当在 chart1 上 hover 点位的时候，获取该点 ID，然后通过 ID 获取到 chart2 的 highchart 对象，获取对应点位以及 tooltip 对象，通过 `point.setState()` 和 `tooltip.refresh()` 来响应事件

```javascript
point: {
    events: {
        mouseOver: function(e) {
            var id = this.series.data[0].id;
            var targetChart = $(elseEle).siblings().highcharts();
            var pointer = targetChart.get(id);
            var tooltip = targetChart.tooltip;
            pointer.setState('hover');
            tooltip.refresh(pointer, e);
        }
    }
},
```
