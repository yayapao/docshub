---
id: features
title: ''
sidebar_label: Features
---

import { DocsHeader } from '/src/components/Layout/DocsHeader'
import {
  HighlightWithBadge,
  HighlightWithCode,
} from '/src/components/Highlights'

<DocsHeader
  title="Sentry Features"
  description="基于 Sentry 平台做贴近业务的功能实现。"
  tags={['features']}
  links={[
    {
      label: 'Customize Your Sentry Workflow: A Sample Internal Integration',
      link: 'https://blog.sentry.io/2019/11/21/customize-your-sentry-workflow-a-sample-internal-integration/',
    },
  ]}
/>{' '}

## 使用 SDK

这里我们以浏览器端接入为例（其他平台接入配置可以参考[docs-platform](https://docs.sentry.io/platforms/javascript/)）其配置如下：

```javascript
import * as Sentry from '@sentry/browser'
import { Integrations } from '@sentry/tracing'

Sentry.init({
  dsn: 'https://examplePublicKey@o0.ingest.sentry.io/0',
  release: 'my-project-name@2.3.12',
  // store 通道的采样率
  smapleRate: 1
  integrations: [new Integrations.BrowserTracing()],
  // envelope 通道的采样率
  tracesSampleRate: 1,
  beforeSend(event, hint) {
    return event
    // return null 会将此次上报丢弃
  }
})
```

`beforeSend(event, hint)` 内的 hint 参数会携带原始异常堆栈信息，可以在此更改指纹来影响 Sentry 对 issues 的聚合方式

```js
beforeSend(event, hint) {
  const error = hint.originalException;
  if (
    error &&
    error.message &&
    error.message.match(/database unavailable/i)
  ) {
    event.fingerprint = ["database-unavailable"];
  }
  return event;
}
```

## Sampling

### 为什么要采样？

最理想的情况是，我们希望将客户端上报的所有数据进行处理并存储，这将为我们在数据分析时提升准确率。

但是，当<strong>海量数据(enormous volume of data)</strong>由客户端进行上报后，服务器的计算成本和数据存储成本将是我们不得不考虑的问题。

在 Sentry 中的具体表现是，性能数据是错误数据的千倍计，同时两者的 context size 几乎相同。

### 设计采样策略的难点？

**采样的难点不在于实现采样本身，而在于如何如何最大化利用上报数据的价值和采样规则的制定。**

在实际业务场景中，如果采样率设置过高，会有成本压力；设置过低又会失去分析数据的准确性。因此这个问题的挑战在于：如何在保证数据准确性的基础上尽力降低成本。

### Sentry 如何设计采样方案？

Sentry 的采样方案经过 3 次进化。

![ds](/img/fte/sentry/sentry_dynamic_sampling.png)

**1.简单的采样启发式**

:::note

所谓采样启发式（sampling heuristics）就是应用一系列静态规则。

:::

该方案是 Sentry 最早采用的采样方案，它会处理客户端上报的所有数据，处理后丢弃 99% 的数据。

存储规则是存储每一个唯一错误，并存储前 100 个样本，之后的样本会随机存储。

该策略没有将所有事件落库索引，而是 Sentry 通过 tags 和其他关键信息（比如操作系统等）来作为聚合因子，聚合后进行高维分析。

**2. 全部存储模型**

第一种策略纵然能够满足大部分用户需求，但是由于用户需求和维护困难。Sentry 放弃了该方案，转而放弃进行采样，而是将全部事件进行存储，在这个过程中，开发人员致力于最小化成本。

这个策略在没有引入性能数据上报通道之后，便不再奏效，原因也很直接：量大！性能数据是错误事件的千倍计，并且携带的内容相差无几。

最终还是需要采样来进行解决，不过这次 Sentry 开放 `sampleRate` 等配置给到用户来自定义采样率。

这么做还是存在问题，即：

- 用户很难准确地配置当前采样率，过高过低都不合适
- 修改采样率需要重新发版上线

**3. Dynamic Sampling 动态采样**

DS 的宗旨是：最大化数据价值。这句话的深层含义是，Sentry 不仅会处理最终落库的数据，同时也会处理被丢弃的数据，以确保聚合等场景的数据准确性。（没有记录不代表没有发生！）

DS 存在两个关键点：

1. 通过预计算的方法，提供更多高维视角的核心指标视图。这将保证你始终能够在高维视角发现问题，并深入研究相关样本
2. 无需修改客户端，即可快速更改采样率来控制对样本数据的采集

Sentry 通过在平台内配置后，将采样的策略通过 Realy 推送到各个边缘节点，允许其半实时地执行采样启发式。

我们参考官方文档的例子进行说明：

![sampling](https://docs.sentry.io/static/3b586576c596282422ed295cfe3a80f1/2a333/server-side-sampling-a.png)

假设我们在客户端 SDK 设置了 50% 的采样率，在服务端设置了 25% 的采样率

那么最终落库（被处理和索引）的样本占**总 transaction volumn** 的 25%，被处理但是不被索引和落库的样本数占**总 transaction volumn** 的 50%。

## Grouping Issues

:::note

错误事件的聚合

:::

在本章，我们将会在[Issue Grouping](https://docs.sentry.io/product/data-management-settings/event-grouping/#grouping-by-stack-trace)的基础上介绍 Sentry 内置聚合规则以及如何自定义聚合规则。

开始之前，我们需要明晰：Sentry 内同时存在 Issues 和 Event 的概念。Issue 是 Error event 按照一定规则聚合后的产物。

现在，我们不妨思考一下：

- 数亿的错误事件是如何被分门别类放到不同的 issue 内？
- 如何设计核心方案以支持用户自定义能力？

### How to group error events?

Sentry 内聚合逻辑的核心在于 <HighlightWithCode bgcolor="#ef613e">fingerprint</HighlightWithCode>。

每个错误都会有按照指定聚合算法生成对应的 fingerprint，Sentry 根据 fingerprint 生成对应的 `Group Hash Code`，并以此来对错误事件进行归类。即相同的 `Group Hash Code` 被归为同一个 `issue`。

我们可以在 `Error details > JSON link > fingerprint property` 内查看置顶错误事件的指纹。

**注意，如果使用内建的聚合规则会展示 `fingerprint: "{{ default }}"`，否则会展示展示的 fingerprint 值。**

### Built-in Grouping Algorithms

相信不少用户都有同样的困扰，明明在页面上展示的错误信息值不一样，为什么会被归纳到同一个 issue 呢？

答案是：Sentry 内置的聚合算法**会根据错误的堆栈追踪信息来生产 fingerprint**。即错误事件的堆栈信息相同，则此类错误事件属于同一个 issue。

:::warning

- 所有的聚合策略，均遵循 `stack trace -> exception -> message` 的次序进行处理，一旦 group hash code 生成，不会继续执行剩下的逻辑
- 仅有 `stack trace` 生成的 group hash code 是可靠的

:::

#### Grouping by stack trace

当错误事件到达时，Sentry 会从提取其 stack trace 数据。**并且 sentry 仅会处理由 SDK 上报并与应用关联的 stack trace frames。**

原因在于：

1. 有一些平台的 SDK 不会上报堆栈追踪信息；
2. 如果仅仅是与项目无关的堆栈信息不一致，错误事件仍然会被归为同一类；

Sentry 在堆栈追踪信息内会提取：

- 模块名；
- 标准化的文件名，比如修订后的 hash 值会被删除掉；
- 标准化的上下文，即受影响的代码（源码，如果能够匹配 sourcemap）

这里我们创建一个方法，在相同的方法内，抛出不同的错误信息：

```js
// 抛出一个Error, value 为当前时间
function sendSentry() {
  throw new Error(new Date().toLocaleString())
}
```

在 Sentry 返回结果：

![group_diff](/img/fte/sentry/sentry_group_diff.png)

根据上图结果我们可以得出：**使用默认的内建聚合规则，在 stack trace 相同的情况下会被聚合到同一个 issue，即使他们的 exception/message 并不相同。**

我们继续在 issue details 页面展开 `EVENT GROUPING INFORMATION` 来对比同一个 issue 内不同 event 的聚合细节，如下所示：

![group_info](/img/fte/sentry/group_information.png)

我们不难发现：**在该 issue 内的错误拥有相同的 `group hash code`，实际上 Sentry 最终也是根据它来确定 event 归属！**

#### Grouping by exception

当 stack trace 无法找到时，Sentry 会使用 exception 的 `type` 和 `value` 字段进行兜底，此时聚合不可靠！

异常信息如下所示：

```
Error: 2022/4/21 18:04:06
  at Error: 2022(/4/21 18:4:6)
  at sendSentry(/main.d1f2e7dbd07e024bf014.hot-update.js:27:11)
  at dispatchDiscreteEvent(/static/js/bundle.js:27074:7)
```

如上所示，type 也就是 exception name，即 Error；value 则为人类可读的描述，即 2022/4/21 18:04:06

#### Fallback Grouping

如果以上都不能奏效时，Sentry 将尝试使用不带任何参数的 message。如果这不可用，将使用完整的 message 属性来进行聚合。

### How to customized Grouping?

实际上，Sentry 内建的聚合规则能够满足我们 80% 以上的使用场景，但是对于或多或少的错误事件我们需要拆分或者聚合来更正确地分析数据，因此我们也迫切需要自定义聚合规则的能力。所幸，Sentry 提供了不同的方案，来帮助用户更科学地归纳错误事件。

- `Merge Issues` 合并已存在 issue
- `Fingerprint Rules` 应用所有新入的错误事件，决定生成 `group hash code` 的规则
- `Stack Trace Rules` 应用所有新入的错误事件，决定生成 `group hash code` 的 stack trace

对于 `Fingerprint Rules` 和 `Stack Trace Rules` 都遵循统一的匹配规则，即：

- 不同行形成**或**的关系
- 统一行不同规则形成**与**的关系

#### Merge Issues

merge issues 是 Sentry 提供最易操作的自定义聚合能力，它用来处理：

1. 多个 issues 类似；
2. 用户希望减少 issue noise，使 issues 面板更加整洁，方便专注于某一类 issue；

`merge issues` 属于事后的人工干预，仅会影响已处理的错误事件以及将来上报的相同的错误事件。其操作方法很简单，在 issues 面板选择不同的 issue 进行合并即可，这里不再赘述。

:::warning

**Sentry 不会根据 merge issues 来推断新的聚合规则，仅当新的错误事件拥有和当前 merged issues 相同的 fingerprint 并生产同样的 group hash code 才会被自动聚合**

:::

#### Fingerprint Rules

Sentry 支持通过配置 `[Project] > Settings > Issue Grouping > FINGERPRINT RULES` 在服务端根据自定义聚合规则。

**注意，配置 fingerprint rules 会覆盖默认的聚合规则**

finterprint rules 遵循如下模式：

```
# partten
matcher:glob -> fingerprint, values title=""
```

比如，我们配置了一条规则 `error.type:ReferenceError -> Not-found-error, {{transaction}}`，它表示匹配所有 type 为 ReferenceError 的错误事件，对其聚合并赋值 fingerprint 为 Not-found-error，同时，使用 `{{ transaction }}` 进行通配，达到按照不同 transaction 进行聚合的目的

在了解基本规则之后，我们希望在对上文的例子进行拆分，即按照不同的 exception 值来对错误事件进行聚合，并在 issue 上自定义标题展示。

首先，我们在项目内配置了一条 fingerprint rule，如下：

```
error.type:Error -> error, {{ error.value }} title="Error from value={{ error.value }}"
```

当我们在客户端再次触发错误时，我们观察到结果如下所示：

![fingerprint-rules](/img/fte/sentry/fingerprint_rules.png)

据此我们可以分析：

1. 根据内建算法对错误事件进行聚合，这些错误拥有相同的堆栈信息和 `group hash code`
2. 当配置如上 `FINGERPRINT RULES` 之后，会对所有 `error.type=Error` 的错误按照 `error.value` 进行分类，且标题展示 `Error from value={{ error.value }}`
3. 根据自定义规则，其 `fingerprint values` 根据 exception 的值而发生变化，导致其 `group hash code` 不尽相同，最终被聚合到不同的 issue

#### Stack Trace Rules

基于 `stack trace` 第一可靠的原则，Sentry 为我们提供在生成 `group hash code` 之前处理 `stack trace` 的能力，它被看作是聚合规则的增强措施。

思路就是在聚合之前，允许我们按照规则修改 `stack trace` 来影响最终聚合结果。

同样，我们可以在 `[Project] > Settings > Issue Grouping > Stack Trace Rules` 内配置相应规则。其 pattern 如下：

```
# Enhancement Rules
matcher-name:expression other-matcher:expression ... action1 action2 ...
```

定义规则支持的标志符：

- `+`: 设置标记
- `-`: 清除标记
- `^`: 应用当前 frame 到栈顶的所有 frame
- `v`: 应当当前 frame 到栈底所有的 frame
- `app`: 在应用内标记/清除标记指定 frame
- `group`: 聚合时添加/清除指定 frame

我们通过使用标志符的组合来达到不同的效果，如下我们列举了一组例子帮助理解：

```
# frame 内绝对路径命中 **/node_modules/** 规则的，聚合时都不会参与计算
stack.abs_path:**/node_modules/** -group

# 标记所有 node_modules 目录下的所有代码为不再应用中
stack.abs_path:**/node_modules/** -app

# native 平台允许的最大帧为 3（从栈顶向下数）
family:native max-frames=3

# 命中 function 为 fetchSavedSearches 的下面所有帧都不会被纳入聚合计算
stack.function:fetchSavedSearches v-group
```

## Integration

:::note
[Integation](https://docs.sentry.io/product/integrations/integration-platform/) 是我们能够介入 Sentry 的处理流程，并根据自己的需求进行开发。
:::

在本章，我们会介绍如何在 Sentry 内创建一个内部集成，来自定义工作流。Sentry 将集成分为：`internal` 和 `public`。

- `internal integation` 仅能被用在你的组织内，创建后会自动应用在组织内所有项目，验证过程相对简单
- `public integation` 能被发布，供所有 Sentry 用户使用，验证过程相对复杂

在 `/settings/[org]/developer-settings/` 按照实际需求选择 integation 并写入基本信息后进行创建（后期也可以根据需求进行修改）。

### 创建一个 Internal Integation

用一句话概括整个流程：**Sentry 将 Issus/Event 发送至服务，由服务进行验证后执行相应动作**

参考 [Internal Integation](https://docs.sentry.io/product/integrations/integration-platform/internal-integration/) 和 [Round Robin Assignment](https://blog.sentry.io/2019/11/21/customize-your-sentry-workflow-a-sample-internal-integration) 进行快速搭建一个内部集成。

这里我们抽离部分核心代码：

```js
// 验证方法，注意 createHmac 的引入方式
export const verifySignature: (
  request: any,
  secret: string
) => Promise<boolean> = async (request, secret) => {
  const { createHmac } = await import('node:crypto')
  const hmac = createHmac('sha256', secret)
  hmac.update(JSON.stringify(request.body), 'utf8')
  const digest = hmac.digest('hex')
  return digest === request.headers['sentry-hook-signature']
}

// webhook API
// 由于 internal integation 对组织内所有应用生效，因此最好设置一个白名单来过滤
@Post()
async doAssigned(
  @Body() body: any,
  @Headers() headers: Record<string, string>,
  @Request() req,
) {
  if (!verifySignature(req, round_robin_assigned_secret)) {
    return failed('bad signature')
  }
  const resource = headers['sentry-hook-resource']
  const { action } = body

  if (resource === 'issue' && action === 'created') {
    const { id: newIssueProjectID } = body.data.issue.project
    // 仅对白名单内应用进行处理
    if (
      Array.isArray(this.whiteProjectIDs) &&
      this.whiteProjectIDs.includes(+newIssueProjectID)
    ) {
      const { id: issueID } = body.data.issue
      // 验证完成之后，开始执行业务逻辑
    }
  }
  return successed({
    body,
    headers,
  })
}
```

### 验证流程

**如果遇到再次启动，integration 不会主动触发的情况，尝试修改 integation 配置并重新保存**

- 启动接受 Sentry Post 的后端服务
- 本地启动 Sentry，并且为 workers 模式
- 通过 sentry-cli 向本地项目发送 event

## Source Maps

:::note Source Maps

Source Maps 是构建时的产物，用来映射源文件，定位源码位置。在 Sentry 内能够展示更具可读性的错误堆栈信息。

:::

在 Sentry 内部支持通过以下两种方式来匹配 Source Maps:

1. **将源文件和 Source Maps 文件上传至平台**，process-worker 在文件系统内寻找 Source Maps 文件进行匹配、替换；
2. process-worker 解析错误堆栈文件名 -> 从线上拉取目标文件 -> 解析 sourceMappingURL -> 拉取 Source Maps -> 执行匹配、替换（此过程需要开启 `Allow JavaScript Source Fetching`）；

针对第一点，我们介绍多种上传方案，包括在工程化阶段、通过 CLI 或者接口。对于第二点，我们会从 Sentry 的实现方面对其核心点进行阐述，同时也会介绍提升请求容忍度的解决方案。

### Upload Source Maps

:::warning Before Upload

1. 需要申请指定权限的 token
2. 需要配置 SDK 和上传时 release 一致
3. 开启 SourceMap，并且源文件和 Source Maps 都需要上传
4. 一般不要暴露 Source Maps 到线上（与打包产物同域）

:::

Sentry 支持三种上传方式：

- 在工程构建阶段，通过构建工具插件上传
- 通过 Sentry API 上传
- 通过 SENTRY-CLI 上传

**请记住，我们执行上传动作时，只是介质不同，最终都是调用上传接口上传文件。**因此，配置通常是通用的：

```ts
const upload_config = {
  // 必传参数
  org: '[organization name]',
  project: '[project name]',
  include: '[output directory]',
  authToken: '[token]',
  url: 'https://sentry.io/',
  release: '[release name]',
  // 可选，上传前清除之前的 artifacts
  cleanArtifacts: true,
  // 避免上报错误信息到 Sentry
  telemetry: false,
}
```

#### vite-plugin

```bash

yarn add --dev @sentry/vite-plugin

```

配置 `vite.config.ts`

```typescript
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'
import path from 'path'
import type { PluginOption } from 'vite'
import sentryVitePlugin from '@sentry/vite-plugin'
import childProcess from 'node:child_process'

export const run = (cmd: string, { unify = false } = {}) => {
  return new Promise((resolve, reject) => {
    childProcess.exec(cmd, {}, (err, stdout, stderr) => {
      let output = ``
      if (unify) {
        output = stdout.toString() + stderr.toString()
      } else {
        output = stdout.toString()
      }
      if (err) {
        reject(err)
      }
      resolve((err ? '' : output).trim())
    })
  })
}

// 这里为了测试，我写了个插件用来在打包完成后删除所有 sourceMap 文件，读者可以自己按需使用或者使用社区方案
// rollup 同样适用
function cleanupSourceMaps(): PluginOption {
  return {
    name: 'cleanupSourceMaps',
    apply: 'build',
    closeBundle: async () => {
      await run(`rm -f ./dist/assets/*.js.map`)
    },
  }
}

const plugins = [react()]

if (process.env.NODE_ENV !== 'development') {
  plugins.push(sentryVitePlugin(upload_config))
}

export default defineConfig({
  // other options
  build: {
    sourcemap: true,
  },
  plugins: [...plugins, cleanupSourceMaps()],
})
```

#### rollup-plugin

rollup 与 vite 配置类似，注意开启 sourcemap 即可：

```js
import sentryRollupPlugin from '@sentry/rollup-plugin'

export default {
  input: './src/index.js',
  plugins: [
    // Put the Sentry rollup plugin after all other plugins
    sentryRollupPlugin(upload_config),
  ],
  output: {
    sourcemap: true, // Source map generation must be turned on
    dir: './dist',
  },
}
```

#### webpack-plugin

```bash
npm install --save-dev @sentry/webpack-plugin
```

配置 `jsconfig.json` 或者 `tsconfig.json` 开启 SourceMap:

```json
{
  "compilerOptions": {
    "inlineSourceMap": true,
    "sourceRoot": "/"
  }
}
// umi 内
{
  "devtool": "source-map",
}
```

**修改 webpack 配置**

这里是一个配置的例子，请根据自身 webpack 配置情况合理修改：

```javascript
const SentryCliPlugin = require('@sentry/webpack-plugin')

module.exports = {
  // 开启 source-map
  devtool: 'source-map',
  configureWebpack: (config) => {
    // 生产环境上传
    if (process.env.NODE_ENV === 'production') {
      config.plugins = [
        ...config.plugins,
        new SentryCliPlugin(upload_config),
        // 上传完毕之后删除 js.map 文件
        new CleanWebpackPlugin({
          cleanAfterEveryBuildPatterns: ['**/*.map'],
          protectWebpackAssets: false,
        }),
      ]
    }
  },
}
```

#### 通过 API 接口

参考[Upload a New Project Release File](https://docs.sentry.io/api/releases/upload-a-new-project-release-file/)的上传接口，参考 [🔒 上传工具](https://github.com/YaYaPao/docscripts/blob/main/sentry/scripts/upload_source_file.py)

快速例子：

```bash
curl -X POST \
  'https://sentry.io/api/0/projects/[org]/[projectName]/releases/[releaseName]/files/' \
  --header 'Authorization: Bearer [token]' \
  --form '[filePath].map'
```

#### 利用 sentry-cli 上传

使用 `sentry-cli` 上传之前，你需要为你的项目的此次发布设置一个平台内独一无二的 **release name**，fems 会用 release 来匹配线上错误和 sourcemap 文件。

下面是具体操作步骤：

1. 创建一个 release，注意 `release_name` 需要和 SDK 配置的 release 字段值一致，且全平台唯一。

```bash
sentry-cli releases new <release_name>
```

2. 上传 Source Maps，如下会把指定目录下所有文件上传到 Sentry，并指定为当前 release_name，注意该文件夹下需要同时包含**部署文件**和**sourceMap 文件**，处理完成后，上传文件会被暂存起来，我们继续执行最后一步来完成发布！

```bash
sentry-cli releases files <release_name> upload-sourcemaps /path/to/files
```

3. 完成发布

```bash
sentry-cli releases finalize <release_name>
```

### Fetch Source Maps Online

除了将文件上传到 Sentry 平台外，我们还可以通过开启 `Allow JavaScript Source Fetching` 来让 Sentry 直接从线上去拉取文件。大家可以思考一下，**为什么 Sentry 不建议这么做？**

:::warning Why not？

1. 存在安全风险
2. 阻塞 Sentry 处理进程

:::

对于**安全风险**，我们从两方面进行解决：

- 对于开发者来说，我们必须将 Source Maps 文件放在线上指定位置（可以通过 rewriteFrame 来改变位置），这样存在源码暴露的风险
- 更重要的是存在 CSRF 安全问题，会将内网环境暴露，比如 Stack Trace 文件名替换成一个脚本地址等

对于 CSRF，我通过自建的白名单机制对其进行解决。

同时，Sentry 会启动 worker 来处理 events，当需要请求线上文件时，会阻塞当前的处理程序，等待拉取文件完毕并写入缓存后，才会继续执行其他任务。这里我们对 Sentry 拉取 Source Maps 内容进行深度解读。

#### Process Source Maps

Sentry 在处理 events 时，会根据 Stack Trace 信息去解析并请求源文件，在拉取回源文件之后，会解析文件内容，获取线上 Source Maps 的路由地址，<HighlightWithBadge label='拉取文件内容并进行缓存' />

Sentry 本身存在两种缓存机制：

- 一种是 Setrny 自己的实现，即结合 Redis 进行缓存；
- 一种是 Django 本身的缓存机制，即通过 memcached 进行缓存，文件内容通常会放在 memcached 服务内进行存储

因此当我们发现**文件内容过大导致不能存储**的错误时，可以从 memcached 配置入手进行改善。
