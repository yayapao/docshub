---
id: observability
title: ''
sidebar_label: Observability
---

import { DocsHeader } from '/src/components/Layout/DocsHeader'
import { sentryTaskIngestProcessor, sentryWorkerProcessor } from './datasets/task.tsx'
import { CommonTable } from '/src/docase/sentry'

<DocsHeader
  title="Sentry Observability"
  description="如何建设 Sentry 系统本身的可观测性"
  tags={['features']}
  links={[]}
/>

Sentry 本身是一个分布式系统，用来采集、分析日志，因此我们在考虑对 Sentry 系统本身的可观测性进行建设时，可以参考通用监控系统。这里我们主要针对 Sentry 平台的稳定性、性能、可用性等方面进行监控。

## Sentry Task 指标拆解

:::warning

这里我们遵从 sentry 本身的指标定义，并在 `src/sentry/utils/metrics.py` 内统一打印。

:::

我们根据不同 runner 记录的指标进行拆解，并主动发起一次错误上报。

**处理 message 到写入 snuba kafka topic 流转过程如图：**

<img src="/img/drawio/sentry-ingest-process.drawio.svg" width="100%" />

- `process_event` 主要执行 `_load_event()`、`_store_event()` 以及 `dispatch_task()` 方法，会进行反序列化、前置过滤、写入缓存等操作

### ingest

ingest 服务记录日志如下，分别打印 `key, value, instance, current_tags, sample_rate`（**注意，这个过程中删除了一些与时间指标/流程无关的日志**）

<CommonTable data={sentryTaskIngestProcessor} index={1} />

在 Sentry 实现中，需要明白 ingest 是一个消费 kafka 数据的服务，它通过 consumer 和 worker 两种实现来分别消费数据、处理数据。在 consumer 服务内，主要对原始消息进行解析、过滤、调度，而 worker 将执行具体的处理。为此，我们阅读源码，理清指标之间的关联关系。

### worker

worker 服务主要是处理 event，将 event 写入到 postgres/tsdb 中，同时会将 event 的相关信息写入到 redis 中，以便后续查询。**不同的 worker 将执行不同的任务。**

worker 相关的服务日志记录如下，这个过程中删除了一些无关紧要或者微粒度的日志。

<CommonTable data={sentryWorkerProcessor} index={1} />

## 使用 prometheus 采集指标

### 指标类型

Prometheus 将指标分为四种类型：`Counter`, `Gauge`, `Histogram`, `Summary`。**指标类型仅在客户端侧和线路协议作区分，服务侧会将所有数据平铺成无类型的时间序列。**

- Counter

  Counter 是一种累计指标，代表一个单调递增的计数器，其值只能增加或归零。比如：请求总数、错误总数等。**不要使用计数器来显示可能会减少的值，比如显示当前进程的数量。**

- Gauge（仪表盘）

  仪表盘是一种度量，代表一个可以任意升降的单一数值，比如温度、进程数量等。

- Histogram（直方图）

  Histogram 对观测值进行采样，并按照可配置桶进行计数。同时它还提供所有观察值的总和。比如：请求持续时间、响应大小等。

- Summary（摘要）

  与直方图类似，摘要对观测值（通常是请求持续时间和响应大小等）进行采样。虽然它也提供观察值的总计数和所有观察值的总和，但它计算的是滑动时间窗口中可配置的量化值。

**如何选择合适的指标类型？**

- 如果需要在 Counter 和 Gauge 之间选择，记住：**如果数值可以下降，则选择 Guage**
- 原始计数器很少使用，使用 `rate()` 可以获取它们每秒的增长速度

## 监测指标

**整体根据不同业务场景进行区分，比如 relay, sentry, sunba 等**

- sinker 是一个术语，通常指数据同步或者传输的工具，用于将数据从一个系统传输到另一个系统，比如将数据从 Kafka 传输到 MySQL，或者从 Kafka 传输到 ClickHouse 等。

### 系统稳定性（黄金指标）

1. **TPS (Transactions Per Second)：每秒事务数**。即每秒钟系统处理的事务数，包括成功和失败的事务。其中**写入 TPS** 表达系统在处理写入请求的效率和性能。

- 理论上，系统接收 TPS 和系统写入 TPS 两者的曲线应该是拟合的，如果出现较大偏差，则表示写入服务出现了阻塞

2. **receiver 接收错误次数**。表达接收服务在处理请求时出现的错误次数，一般是没有数据的，通常发生在用户上报了错误数据、或者系统本身出现了错误。

3. **sinker 写入失败错误次数**。表达数据存储过程中，发生失败的次数统计。正常情况下是没有数据的。

4. **receiver 接收耗时小于 10ms 占比**。表达接收服务处理效率。

5. **sinker 写入耗时占比**。表达数据写入服务的处理效率。

### 消息接收分析

1. **kafka 每秒输入数据量**。表达不同 topic 的概览。

2. **receiver 消息接收 TPS**。

3. **sinker 消息接收 TPS**。

4. **receiver 消息接收总量**。

5. **sinker 消息接收总量**。

### sinker 消息写入分析

1. **sinker 接收单条消息平均大小**。按照不同项目进行统计。

2. **sinker 写入消息的大小**。

3. **sinker 写入消息的数量**。

### 客户端指标上报

1. **客户端指标上报次数 QPS**。

2. **上报通道 TPS**。表达不同上报通道的处理效率，包括 events/transaction。

3. **上报量分布**。不同通道在一定时间范围内的上报量分布占比。

### receiver 部署实例资源分析

1. **receiver CPU 使用率**。按照不同实例分布。

2. **receiver 内存使用率**。按照不同实例分布。

### sinker 部署实例资源分析

1. **sinker CPU 使用率**。按照不同实例分布。

2. **sinker 内存使用率**。按照不同实例分布。

3. **sinker 写入 TPS**。按照不同实例分布。
