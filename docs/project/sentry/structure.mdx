---
id: structure
title: ''
sidebar_label: Structure
---

import { DocsHeader } from '/src/components/Layout/DocsHeader'
import {
  HighlightWithCode,
  HighlightWithText,
} from '/src/components/Highlights/TextContent'
import { ResolvedTag } from '/src/components/Highlights/CustomizedTag'

<DocsHeader
  title="Sentry Structure"
  description="Sentry server & SDK structure."
  tags={['structure']}
  links={[
    {
      label: `Snuba Structure`,
      link: 'https://getsentry.github.io/snuba/architecture/overview.html',
    },
    {
      label: `Sentry: Event Ingestion Pipeline`,
      link: 'https://getsentry.github.io/event-ingestion-graph/',
    },
    {
      label: '单体系统时代',
      link: 'http://icyfenix.cn/architecture/architect-history/monolithic.html',
    },
  ]}
/>{' '}

## Background

通过对 Sentry 架构进行深入研究，充分利用其基于队列的设计模式，对服务、worker 均进行细致拆分，输出一套微服务架构的部署方案。

在开始介绍之前，我们先聊聊背景。

![sentry_structure_background](/img/fte/sentry/sentry_structure_background.png)

旧版本的 Sentry 是一个巨石应用(Monolithic Application)。**它天然存在着隔离和自治能力上的缺陷，如果一部分代码导致进程资源被过度使用，最终会影响到整个程序。** 因此 old sentry 存在严重的性能瓶颈，同时为了能够 cover 住业务的量，我们不得不去部署多套，为此造成了更严重的资源浪费。并且我们对平台功能定制也无能为力 👐。

:::tip Monilithic Apploication - wikipedia

Monolith means composed all in one piece. The Monolithic application describes a single-tiered software application in which different components combined into a single program from a single platform.

单体意味着自包含。单体应用描述了一种由同一技术平台的不同组件构成的单层软件。

:::

为此，我提出了升级计划。经过调研我发现，在 Sentry 社区内提供了 [self_hosted](https://github.com/getsentry/self-hosted) 方案，**它最终输出 docker-compose。**这意味着我不得不去申请一个高规格的 pod 将所有服务跑起来，根据测试在 42C128G 的情况下，QPS 达到 30 服务就无法正常运行了，这显然无法满足需求，同时其表现为一个类巨石应用，并没有解决 old sentry 的遗留问题。

## Microservices Structure

为此，通过对 Sentry 架构进行深入研究和理解，我提出了一套微服务架构的部署方案。**巨石应用和微服务架构最大的区别在于：巨石应用是进程内调用，而微服务架构是进程间通信。**这里我利用其基于队列的设计模式，将服务进行拆分，同时将 big worker 拆分成更细粒度的 worker，worker 之间基于 celery 进行通信。

## Relay

在 Sentry 架构中，relay 扮演代理服务的角色（或者 Sentry 基础设施），它对 client 上报数据进行应答，同时向 Sentry 请求项目配置，以对 event 执行 parse、normalized、inbound filters、rate limits、datascrub、PII 等处理，最终将事件写入 kafka。

![sentry_relay_diagram](/img/fte/sentry/sentry_relay_diagram.png)

这里展示 relay 处理事件的内部时序图。

:::caution

In a highly concurrent burst of requests should quickly result in eventually consistent and correct status codes.

**在高并发的场景下，应该迅速返回一致且正确的状态码（即 200）**

:::

按照此原则，可能出现我们返回 200，但是事件最终没有被处理的情况，因为真正开始处理事件是一个异步过程，这是一种在返回速率和数据准确率之间的妥协。

1. 当请求到达 relay endpoint 时，会**执行预检查策略**，如果结果不符合预期，则迅速返回 4xx(429-rate_limit, 4xx-invalid_auth_information)，否则会将事件提交给 Redis 队列。在此过程会主动从 ProjectCache 内拉取项目配置。

**注意，此时拉去不到项目配置或者配置过期，并不会继续向 Sentry 发送请求，而是认为事件不合法。**

检查策略包括：

- 当前项目是否存在？项目是否处于激活状态？
- 当前是否正在执行速率限制？
- 项目的 DSN 是否正确？

2. EnvelopeManager 通过 Redis 队列消费数据，解析后返回 200（携带 EventID），随后开始真正处理事件（这是一个异步处理过程！）

- EnvelopeManager 会向 ProjectCache 主动拉取项目配置。**如果项目配置被清除或者过期，Relay 会向 Sentry 发送获取项目配置请求，并尽可能一次拉取多个项目的配置，以减少 Sentry 服务的压力；**
- 解析事件，对数据进行解压缩、检查 json 合法性、提取事件内的 eventID 并将其写入 response。**这里 relay 已经创建了 `Event` 结构体，这一步需要申请内存；**
- 事件标准化处理。为 Event 结构体赋值，这是 relay 中最消耗 CPU 算力的一个任务单元，此时会丢弃不合法的数据；
- 过滤事件（inbound-filter），在这一步会应用配置的过滤规则，比如 IP addresses, partterns 等。被过滤的事件会被丢弃；
- 速率限制。这里所说的速率限制是指，为每一个项目建立配额（_quatos_），如果超过限额则会将配置写入内存中，以避免该项目的新增事件被写入 redis 队列，**配额通常发生在 Sentry sass 平台上；**
- 清洗数据。根据 PII 和 datascrubbing config 对数据进行处理；

3. 将事件写入 Kafka，写入 `outcomes` 和 `ingest-event` topic 供 Sentry consumer 消费，其中 outcomes 被处理后最终被 snuba 消费并写入 TSDB。

- outcomes 主要对 Sentry 内的计数器负责，用来表达每个事件的处理结果，以及不是正常处理的原因，参考 [category 在 relay 内定义](https://github.com/getsentry/relay/blob/master/relay-common/src/constants.rs#:~:text=pub%20enum%20DataCategory,%7D)

**outcomes 数据结构**

```json

{
    "timestamp": timestamp,
    "org_id": org_id,
    "project_id": project_id,
    "key_id": key_id,
    "outcome": outcome.value, // 事件处理结果
    "reason": reason,
    "event_id": event_id,
    "category": category, // 事件类型
    "quantity": quantity,
}

```

**outcomes 结果**

```py

class Outcome(IntEnum):
    ACCEPTED = 0
    FILTERED = 1
    RATE_LIMITED = 2
    INVALID = 3
    ABUSE = 4
    CLIENT_DISCARD = 5

```

## Snuba

:::info

**Search the seas for your lost treasure.**

:::

正如 snuba github 简介上描述的一样，**Snuba 是一个在 clickhouse 基础上提供丰富数据模型的服务，同时它还具备高效的数据摄取和查询优化能力。**

CK 表结构如下图，与 Snuba 服务相关联的主要有 **errors、transactions、outcomes、sessions**

![snuba-tables.png](https://img.joyjoy.cc/project/snuba-tables.png)

### 整体架构

![structure-overview](https://getsentry.github.io/snuba/_images/overview.png)

**一句话表达：从 kafka 消费回来的数据会全部写入 CK 表和物化视图内，数据支持时间点查询和流式查询（订阅）。**

Snuba 利用 CK 支持多种数据引擎的特性，通过选择合适的引擎，可以从底层数据上处理重复数据、保持数据一致性。

### Snuba 数据链路（Sentry 架构内）

CK 数据表相关源码查看 [snuba/datasets](https://github.com/getsentry/snuba/tree/21.9.0/snuba/datasets)，包括数据表定义、物化视图定义、索引定义，以及数据处理逻辑。

#### Errors & Transactions

![sentry_snuba_errors_transactions](https://getsentry.github.io/snuba/_images/errors_transactions_deployment.png)

:::caution

errors 和 transaction 在 Snuba 服务内，处理流程相同，只是数据表不同

:::

其中 `events` topic 被多个 group 消费：

    1. `snuba-consumer` 消费 `events` topic，将数据写入 **CK** 内
    2. `snuba-subscriptions-consumer` 同步消费 `events` topic 和 `snuba-commit-log` topic（由 snuba-consumer 生产），将数据写入 `subscriptions-results` topic 内
    3. `replacements` topic 基于 `events` topic 产生，由 `replacements-consumer` 消费，主要针对非常规处理事件，比如 reprocessing/merge/unmerge 的事件，消费后将结果写入 **redis**，由 `snuba-subscriptions-consumer` 统一处理
    4. Sentry 内服务 `post-process-forwarder` 也会同步消费 `events` topic 和 `snuba-commit-log` topic，之后执行生产逻辑，比如 webhooks 发送等

[**errors 数据、实例展示**](https://github.com/YaYaPao/docscripts/blob/main/sentry/data/ck.md#errors)

[**transactions 数据、实例展示**](https://github.com/YaYaPao/docscripts/blob/main/sentry/data/ck.md#transactions)

#### sessions

![sentry_snuba_sessions](https://getsentry.github.io/snuba/_images/sessions_deployment.png)

:::caution

**Sessions 数据主要服务于 Release Health**

:::

**sessions 数据从 relay 服务写入 ingest-sessions 队列后，由 snuba-sessions-consumer 消费，写入 CK 内**

- 涉及 CK 表为 `sessions_raw_local` 和 `sessions_raw_dist`，以及物化视图 `sessions_hourly_local` 和 `sessions_hourly_mv_local`
- `session-subscriptions-consumer` **同步消费** `ingest-sessions` 和 `sessions-commit-log` topic，根据项目订阅数据，将处理结果写入 `session-subscription-results` 队列中

[**sessions 数据、实例展示**](https://github.com/YaYaPao/docscripts/blob/main/sentry/data/ck.md#sessions)

#### outcomes

![sentry_snuba_outcomes](https://getsentry.github.io/snuba/_images/outcomes_deployment.png)

:::caution

**Outcomes 数据主要服务于 Sentry 平台上的数据统计页面**

:::

与 sessions 数据链路流转类似，outcomes 数据也是从 relay 直接怼到 snuba

- 涉及 CK 表为 `outcomes_raw_local` 和 `outcomes_raw_dist`，以及物化视图 `outcomes_hourly_local`

[**outcomes 数据、实例展示**](https://github.com/YaYaPao/docscripts/blob/main/sentry/data/ck.md#outcomes)

**这里 category 对应 relay 中对 event 的分类，outcome 对应 event 的处理结果，reason 对应 event 处理失败的原因。**
